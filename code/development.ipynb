{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import *\n",
    "import time\n",
    "\n",
    "from dataset import IntentDataset, batch_function\n",
    "from model import CapsuleNetwork\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import tool\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "a = Random()\n",
    "a.seed(1)\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "def setting(train_set, test_set, embedding):\n",
    "    vocab_size, word_emb_size = embedding.shape\n",
    "    max_time = sorted(train_set, reverse=True, key=lambda x: x['length'])[0]\n",
    "    train_num = len(train_set)\n",
    "    test_num = len(test_set)\n",
    "    s_cnum = len(train_set.class_list)\n",
    "    u_cnum = len(test_set.class_list)\n",
    "    config = {}\n",
    "    config['keep_prob'] = 0.8 # embedding dropout keep rate\n",
    "    config['hidden_size'] = 32 # embedding vector size\n",
    "    config['batch_size'] = 64 # vocab size of word vectors\n",
    "    config['vocab_size'] = vocab_size # vocab size (10895) after subtracting padding\n",
    "    config['num_epochs'] = 200 # number of epochs\n",
    "    config['max_time'] = max_time\n",
    "    config['sample_num'] = train_num # sample number of training data\n",
    "    config['test_num'] = test_num # number of test data\n",
    "    config['s_cnum'] = s_cnum # seen class num\n",
    "    config['u_cnum'] = u_cnum # unseen class num\n",
    "    config['word_emb_size'] = word_emb_size # embedding size of word vectors (300)\n",
    "    config['d_a'] = 20 # self-attention weight hidden units number\n",
    "    config['output_atoms'] = 10 # capsule output atoms\n",
    "    config['r'] = 3 # self-attention weight hops\n",
    "    config['num_routing'] = 2 # capsule routing num\n",
    "    config['alpha'] = 0.0001 # coefficient of self-attention loss\n",
    "    config['margin'] = 1.0 # ranking loss margin\n",
    "    config['learning_rate'] = 0.0001\n",
    "    config['sim_scale'] = 4 # sim scale\n",
    "    config['nlayers'] = 2 # default for bilstm\n",
    "    config['ckpt_dir'] = './saved_models/' # check point dir\n",
    "    return config\n",
    "\n",
    "def get_sim(train_set, test_set):\n",
    "    \"\"\"\n",
    "    get unseen and seen categories similarity.\n",
    "    \"\"\"\n",
    "    seen = normalize(torch.stack(list(train_set.class_w2v.values())))\n",
    "    unseen = normalize(torch.stack(list(test_set.class_w2v.values())))\n",
    "    sim = tool.compute_label_sim(unseen, seen, config['sim_scale'])\n",
    "    return torch.from_numpy(sim)\n",
    "\n",
    "def _squash(input_tensor):\n",
    "    norm = torch.norm(input_tensor, dim=2, keepdim=True)\n",
    "    norm_squared = norm * norm\n",
    "    return (input_tensor / norm) * (norm_squared / (0.5 + norm_squared))\n",
    "\n",
    "def update_unseen_routing(votes, config, num_routing=3):\n",
    "    votes_t_shape = [3, 0, 1, 2]\n",
    "    r_t_shape = [1, 2, 3, 0]\n",
    "    votes_trans = votes.permute(votes_t_shape)\n",
    "    num_dims = 4\n",
    "    input_dim = config['r']\n",
    "    output_dim = config['u_cnum']\n",
    "    input_shape = votes.shape\n",
    "    logit_shape = np.stack([input_shape[0], input_dim, output_dim])\n",
    "    logits = torch.zeros(logit_shape[0], logit_shape[1], logit_shape[2]).cuda()\n",
    "    activations = []\n",
    "\n",
    "    for iteration in range(num_routing):\n",
    "        route = F.softmax(logits, dim=2).cuda()\n",
    "        preactivate_unrolled = route * votes_trans\n",
    "        preact_trans = preactivate_unrolled.permute(r_t_shape)\n",
    "\n",
    "        # delete bias to fit for unseen classes\n",
    "        preactivate = torch.sum(preact_trans, dim=1)\n",
    "        activation = _squash(preactivate)\n",
    "        # activations = activations.write(i, activation)\n",
    "        activations.append(activation)\n",
    "        # distances: [batch, input_dim, output_dim]\n",
    "        act_3d = torch.unsqueeze(activation, 1)\n",
    "        tile_shape = np.ones(num_dims, dtype=np.int32).tolist()\n",
    "        tile_shape[1] = input_dim\n",
    "        act_replicated = act_3d.repeat(tile_shape)\n",
    "        distances = torch.sum(votes * act_replicated, dim=3)\n",
    "        logits = logits + distances\n",
    "\n",
    "    return activations[num_routing-1], route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Variables\n"
     ]
    }
   ],
   "source": [
    "data_prefix = '../data/nlu_data/'\n",
    "w2v_path = data_prefix + 'wiki.en.vec'\n",
    "training_data_path = data_prefix + 'train_shuffle.txt'\n",
    "test_data_path = data_prefix + 'test.txt'\n",
    "\n",
    "seen_classes = ['music', 'search', 'movie', 'weather', 'restaurant']\n",
    "unseen_classes = ['playlist', 'book']\n",
    "\n",
    "train_set = IntentDataset(seen_classes, w2v_path, training_data_path)\n",
    "test_set = IntentDataset(unseen_classes, w2v_path, test_data_path)\n",
    "\n",
    "embedding = train_set.embedding\n",
    "categorical = train_set.categorical\n",
    "config = setting(train_set, test_set, embedding)\n",
    "similarity = get_sim(train_set, test_set).to(device)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True,\n",
    "                          collate_fn=batch_function, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'], shuffle=True,\n",
    "                         collate_fn=batch_function, num_workers=4)\n",
    "\n",
    "model = CapsuleNetwork(config).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True, threshold=0.001)\n",
    "\n",
    "if os.path.exists(config['ckpt_dir'] + 'best_model.pt'):\n",
    "    print(\"Restoring weights from previously trained rnn model.\")\n",
    "    model.load_state_dict(torch.load(config['ckpt_dir'] + 'best_model.pt' ))\n",
    "else:\n",
    "    print('Initializing Variables')\n",
    "    if not os.path.exists(config['ckpt_dir']):\n",
    "        os.mkdir(config['ckpt_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           zero-shot intent detection test set performance        \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5739    0.4658    0.5142      1943\n",
      "           1     0.5558    0.6591    0.6031      1971\n",
      "\n",
      "   micro avg     0.5631    0.5631    0.5631      3914\n",
      "   macro avg     0.5649    0.5624    0.5586      3914\n",
      "weighted avg     0.5648    0.5631    0.5590      3914\n",
      "\n",
      "test_acc 0.5631067961165048\n",
      "best_acc 0.6328564128768523\n",
      "Testing time 1.2095\n",
      "Epoch: 23\t| Batch: 001/155\t| Batch Loss: 7.8137\t| Acc: 92.19%\n",
      "Epoch: 23\t| Batch: 051/155\t| Batch Loss: 6.9295\t| Acc: 92.19%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ea54c8b1f0c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ea54c8b1f0c3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, train_loader, config, model, embedding, train_time)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mclone_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch, train_loader, config, model, embedding, train_time):\n",
    "    model.train()\n",
    "    avg_acc = 0\n",
    "    avg_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        input = batch.sentences_w2v.cuda()\n",
    "        lengths = batch.lengths\n",
    "        target = batch.label_onehot.cuda()\n",
    "        label_w2v = batch.label_w2v\n",
    "        \n",
    "        batch_size = len(input)\n",
    "        hc = (Variable(torch.zeros(4, input.shape[0], config['hidden_size'])).cuda(),\n",
    "              Variable(torch.zeros(4, input.shape[0], config['hidden_size'])).cuda())\n",
    "\n",
    "        output = model(input, lengths, embedding.cuda(), hc)\n",
    "        loss = model.loss(target.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        clone_logits = model.logits.detach().clone()\n",
    "        pred = torch.argmax(clone_logits, 1).cpu()\n",
    "        acc = accuracy_score(categorical(target.cpu()), pred)\n",
    "        if idx % 50 == 0:\n",
    "            print(\"Epoch: {}\\t| Batch: {:03d}/{}\\t| Batch Loss: {}\\t| Acc: {}%\".format(\n",
    "                epoch, (idx+1), len(train_loader), round(loss.item(), 4), round(acc * 100., 2)))\n",
    "        avg_loss += loss.item()\n",
    "        avg_acc += acc\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    train_time += epoch_time\n",
    "    avg_loss /= len(train_loader)\n",
    "    avg_acc /= len(train_loader)\n",
    "    \n",
    "    print(\"Epoch: {}\\t| Average Loss: {}\\t| Average Acc: {}%\\t| Train Time: {}s\".format(\n",
    "          epoch, round(avg_loss, 4), round(avg_acc * 100., 2), round(train_time, 2)))\n",
    "\n",
    "    return avg_loss, avg_acc, train_time\n",
    "\n",
    "def test(epoch, test_loader, config, model, embedding, similarity):\n",
    "    # zero-shot testing state\n",
    "    # seen votes shape (110, 2, 34, 10)\n",
    "    # get unseen and seen categories similarity\n",
    "    # sim shape (8, 34)\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            input = batch.sentences_w2v.cuda()\n",
    "            lengths = batch.lengths\n",
    "            target = batch.label_onehot.long().cuda()\n",
    "            label_w2v = batch.label_w2v\n",
    "        \n",
    "            batch_size = len(input)\n",
    "            hc = (Variable(torch.zeros(4, input.shape[0], config['hidden_size'])).cuda(),\n",
    "                  Variable(torch.zeros(4, input.shape[0], config['hidden_size'])).cuda())\n",
    "\n",
    "            output = model.forward(input, lengths, embedding.cuda(), hc)\n",
    "            attentions, seen_logits, seen_votes, seen_weights_c = model.attention, model.logits, \\\n",
    "                                                                  model.votes, model.weights_c\n",
    "            sim = similarity.unsqueeze(0)\n",
    "            sim = sim.repeat(seen_votes.shape[1], 1, 1).unsqueeze(0)\n",
    "            sim = sim.repeat(seen_votes.shape[0], 1, 1, 1)\n",
    "            seen_weights_c = seen_weights_c.unsqueeze(-1)\n",
    "            seen_weights_c = seen_weights_c.repeat(1, 1, 1, config['output_atoms'])\n",
    "            mul = seen_votes * seen_weights_c\n",
    "\n",
    "            # compute unseen features\n",
    "            # unseen votes shape (110, 2, 8, 10)\n",
    "            unseen_votes = torch.matmul(sim, mul)\n",
    "\n",
    "            # routing unseen classes\n",
    "            u_activations, u_weights_c = update_unseen_routing(unseen_votes, config, 3)\n",
    "            unseen_logits = torch.norm(u_activations, dim=-1)\n",
    "            batch_pred = torch.argmax(unseen_logits, dim=1).unsqueeze(1).cuda()\n",
    "            \n",
    "            if idx == 0:\n",
    "                total_pred = batch_pred\n",
    "                total_target = target\n",
    "            else:\n",
    "                total_pred = torch.cat((total_pred.cuda(), batch_pred))\n",
    "                total_target = torch.cat((total_target.cuda(), target))\n",
    "                \n",
    "    print (\"           zero-shot intent detection test set performance        \")\n",
    "    cpu_target = categorical(total_target.cpu())\n",
    "    cpu_pred = total_pred.flatten().cpu()\n",
    "    acc = accuracy_score(cpu_target, cpu_pred)\n",
    "    print (classification_report(cpu_target, cpu_pred, digits=4))\n",
    "            \n",
    "    test_time = time.time() - start_time      \n",
    "    return acc, test_time\n",
    "\n",
    "best_acc = 0\n",
    "train_time, test_time = 0, 0\n",
    "\n",
    "for epoch in range(1, config['num_epochs'] + 1):\n",
    "    train_loss, train_acc, train_time = train(epoch, train_loader, config, model, embedding, train_time)\n",
    "    clear_output(wait=True)\n",
    "    test_acc, test_time = test(epoch, test_loader, config, model, embedding, similarity)\n",
    "    scheduler.step(test_acc)\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), config['ckpt_dir'] + 'best_model.pt')\n",
    "\n",
    "    print(\"test_acc\", test_acc)\n",
    "    print(\"best_acc\", best_acc)\n",
    "    print(\"Testing time\", round(test_time, 4))\n",
    "\n",
    "print(\"Overall training time\", train_time)\n",
    "print(\"Overall testing time\", test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
